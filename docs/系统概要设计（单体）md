# 知识图谱可视化与管理平台 - 系统概要设计（单体部署）

## 1. 系统架构概述

### 1.1 设计目标
基于系统设计需求文档，构建一个单体部署的知识图谱可视化与管理平台，实现知识图谱的创建、编辑、可视化、分析和导入导出功能，满足数据分析师、研究人员、知识工程师等专业用户的需求。

### 1.1.1 架构原则
- **单体架构**：所有功能模块集成在一个应用中，简化部署和维护
- **本地优先**：数据存储在本地，确保数据安全和隐私
- **模块化设计**：功能模块高内聚、低耦合，便于扩展
- **技术栈统一**：基于Python生态系统，减少技术复杂度
- **技术约束适配**：遵循系统设计需求中"### 7.1 技术约束"的核心要求

### 1.1.2 技术栈映射
根据技术约束要求，将原设计技术栈映射到Python单体架构：

| 原设计技术栈 | 单体部署技术栈 | 说明 | 技术约束适配 |
|-------------|---------------|------|-------------|
| React + TypeScript + AntV G6 | Dash + Plotly + NetworkX | Python Web框架和可视化库 | 保持可视化能力，适配Python生态 |
| Spring Boot + TinkerPop Gremlin Server | Flask + NetworkX + 自定义API | Python后端框架和图处理库 | 单体部署，无需独立服务器 |
| JanusGraph图数据库 | NetworkX内存图 + JSON持久化 | Python图处理库和本地文件存储 | 本地存储，符合单机部署 |
| WebSocket/HTTP2 | Flask内置HTTP服务器 | 单体应用通信 | 简化通信机制 |

### 1.1.3 整体架构
本系统采用基于Python的Web应用架构，使用Dash框架构建前端界面，结合NetworkX进行图算法处理，Plotly实现数据可视化。系统采用模块化设计，各模块职责清晰，便于维护和扩展。

```
┌─────────────────────────────────────────────────────────────┐
│                    Web Browser (前端)                        │
├─────────────────────────────────────────────────────────────┤
│                    Dash Framework                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │  UI Components │  │  Callbacks  │  │   Assets    │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
├─────────────────────────────────────────────────────────────┤
│                    应用层 (Application Layer)                │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ Web App Main│  │Interaction  │  │  Ontology   │        │
│  │             │  │  Handler    │  │ Components  │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
├─────────────────────────────────────────────────────────────┤
│                    业务逻辑层 (Business Layer)               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ Knowledge   │  │ Visualization│  │   Utils     │        │
│  │   Graph     │  │              │  │             │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
├─────────────────────────────────────────────────────────────┤
│                    数据层 (Data Layer)                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │   JSON      │  │     CSV     │  │   Excel     │        │
│  │   Files     │  │    Files    │  │   Files     │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 技术栈
- **前端框架**: Dash (基于React)
- **后端语言**: Python 3.8+
- **可视化库**: Plotly
- **图算法库**: NetworkX
- **数据处理**: Pandas
- **NLP处理**: spaCy, NLTK, transformers
- **机器学习**: scikit-learn, PyTorch
- **文档处理**: pdfplumber, python-docx, openpyxl
- **邮件处理**: poplib, imaplib
- **配置管理**: JSON配置文件
- **文件格式**: JSON, CSV, Excel, OWL, RDF, PDF, Word

### 1.3 设计原则
- **模块化设计**: 各功能模块独立，便于维护和测试
- **松耦合**: 模块间通过明确的接口交互
- **可扩展性**: 支持新功能模块的添加
- **可配置性**: 通过配置文件控制系统行为
- **数据驱动**: 基于数据模型驱动界面展示

## 2. 系统模块设计

### 2.1 核心模块结构

```
src/
├── knowledge_management/     # 知识管理模块
│   ├── application/         # 应用层
│   │   └── ontology_generator.py # 本体生成器应用服务
│   ├── domain/              # 领域层
│   │   └── model/           # 领域模型
│   │       ├── graph.py     # 知识图谱主类
│   │       ├── node.py      # 节点类
│   │       ├── edge.py      # 边类
│   │       └── ontology.py  # 本体类
│   └── infrastructure/      # 基础设施层
├── email_ingestion/         # 邮件接收模块
│   ├── application/         # 应用层
│   │   └── email_service.py # 邮件服务
│   ├── domain/              # 领域层
│   │   ├── model/           # 领域模型
│   │   │   └── email.py     # 邮件实体
│   │   └── repository/      # 仓储接口
│   │       └── email_repository.py
│   └── infrastructure/      # 基础设施层
│       ├── pop3_adapter.py  # POP3适配器
│       └── file_email_repository.py
├── nlp_processing/          # ⭐ 新增：NLP处理模块
│   ├── __init__.py
│   ├── entity_extractor.py  # 实体抽取器
│   ├── relation_extractor.py # 关系抽取器
│   ├── text_preprocessor.py # 文本预处理器
│   ├── document_parser.py   # 文档解析器
│   └── models/              # NLP模型
│       ├── ner_model.py     # 命名实体识别模型
│       └── relation_model.py # 关系抽取模型
├── ml_enhancement/           # ⭐ 新增：机器学习增强模块
│   ├── __init__.py
│   ├── entity_alignment.py  # 实体对齐
│   ├── semantic_resolution.py # 语义消解
│   ├── relation_inference.py # 关系推理
│   ├── similarity_calculator.py # 相似度计算
│   ├── clustering_analyzer.py # 聚类分析
│   └── anomaly_detector.py  # 异常检测
├── interfaces/              # 接口层
│   └── web_app/             # Web应用接口
│       ├── web_app_main.py  # 主应用入口
│       ├── interaction_handler.py # 交互处理器
│       └── ontology_components.py # 本体组件
├── shared/                  # 共享模块
│   ├── config.py            # 配置管理
│   └── utils/               # 工具类
│       ├── data_loader.py   # 数据加载器
│       └── import_export.py # 导入导出处理
└── assets/                  # 静态资源
    └── style.css           # 样式文件
```

### 2.2 模块职责说明

#### 2.2.1 知识管理模块 (knowledge_management)
**职责**: 提供知识图谱的核心数据结构和本体管理功能

**主要类**:
- `KnowledgeGraph`: 知识图谱主类，管理节点和边的集合
- `Node`: 节点类，表示知识图谱中的实体
- `Edge`: 边类，表示实体间的关系
- `KnowledgeOntology`: 本体类，管理本体结构
- `OntologyGenerator`: 本体生成器，从图谱生成本体

#### 2.2.2 邮件接收模块 (email_ingestion)
**职责**: 处理邮件的接收、解析和存储

**主要类**:
- `Email`: 邮件实体类
- `EmailService`: 邮件处理应用服务
- `POP3Adapter`: POP3协议适配器
- `EmailRepository`: 邮件仓储接口

#### 2.2.3 NLP处理模块 (nlp_processing) ⭐ 新增
**职责**: 提供自然语言处理和知识抽取功能

**主要类**:
- `EntityExtractor`: 实体抽取器，识别文本中的命名实体
- `RelationExtractor`: 关系抽取器，识别实体间的语义关系
- `TextPreprocessor`: 文本预处理器，进行分词、词性标注等
- `DocumentParser`: 文档解析器，支持PDF、Word、Excel等格式
- `NERModel`: 命名实体识别模型
- `RelationModel`: 关系抽取模型

#### 2.2.4 机器学习增强模块 (ml_enhancement) ⭐ 新增
**职责**: 提供机器学习算法增强知识图谱质量

**主要类**:
- `EntityAlignment`: 实体对齐器，识别和合并重复实体
- `SemanticResolution`: 语义消解器，解决实体歧义问题
- `RelationInference`: 关系推理器，基于现有关系推断新关系
- `SimilarityCalculator`: 相似度计算器
- `ClusteringAnalyzer`: 聚类分析器
- `AnomalyDetector`: 异常检测器

#### 2.2.5 接口层 (interfaces)
**职责**: 提供Web界面和用户交互功能

**主要组件**:
- `create_app()`: 应用创建和配置
- `InteractionHandler`: 处理用户交互逻辑
- `OntologyVisualizer`: 本体可视化组件

#### 2.2.6 共享模块 (shared)
**职责**: 提供通用的工具和服务功能

**主要类**:
- `Config`: 配置管理器
- `DataLoader`: 数据加载器
- `DataImportExport`: 数据导入导出处理器

## 3. 数据模型设计

### 3.1 核心数据结构

#### 3.1.1 节点 (Node)
```python
class Node:
    def __init__(self, 
                 node_id: Optional[str] = None,
                 label: str = "",
                 node_type: str = "default",
                 properties: Optional[Dict[str, Any]] = None,
                 x: Optional[float] = None,
                 y: Optional[float] = None):
        self.id = node_id or str(uuid.uuid4())
        self.label = label
        self.type = node_type
        self.properties = properties or {}
        self.x = x
        self.y = y
```

**字段说明**:
- `id`: 节点唯一标识符
- `label`: 节点显示标签
- `type`: 节点类型（如person、organization等）
- `properties`: 节点属性字典
- `x, y`: 节点在可视化中的坐标

#### 3.1.2 边 (Edge)
```python
class Edge:
    def __init__(self,
                 source_id: str,
                 target_id: str,
                 edge_id: Optional[str] = None,
                 label: str = "",
                 edge_type: str = "default",
                 properties: Optional[Dict[str, Any]] = None,
                 weight: float = 1.0):
        self.id = edge_id or str(uuid.uuid4())
        self.source_id = source_id
        self.target_id = target_id
        self.label = label
        self.type = edge_type
        self.properties = properties or {}
        self.weight = weight
```

**字段说明**:
- `id`: 边唯一标识符
- `source_id`: 源节点ID
- `target_id`: 目标节点ID
- `label`: 边显示标签
- `type`: 边类型（如works_at、located_in等）
- `properties`: 边属性字典
- `weight`: 边权重

#### 3.1.3 知识图谱 (KnowledgeGraph)
```python
class KnowledgeGraph:
    def __init__(self):
        self.nodes: Dict[str, Node] = {}
        self.edges: Dict[str, Edge] = {}
        self._nx_graph = nx.Graph()
```

**核心方法**:
- `add_node(node: Node)`: 添加节点
- `add_edge(edge: Edge)`: 添加边
- `remove_node(node_id: str)`: 删除节点
- `remove_edge(edge_id: str)`: 删除边
- `get_neighbors(node_id: str)`: 获取邻居节点
- `search_nodes(query: str)`: 搜索节点
- `get_statistics()`: 获取统计信息

### 3.2 数据交换格式

#### 3.2.1 JSON格式
```json
{
  "nodes": [
    {
      "id": "node_1",
      "label": "张三",
      "type": "person",
      "properties": {
        "age": 30,
        "department": "技术部"
      },
      "x": 100.0,
      "y": 200.0
    }
  ],
  "edges": [
    {
      "id": "edge_1",
      "source_id": "node_1",
      "target_id": "node_2",
      "label": "工作于",
      "type": "works_at",
      "properties": {
        "start_date": "2020-01-01"
      },
      "weight": 1.0
    }
  ],
  "metadata": {
    "export_timestamp": "2024-12-01T10:00:00",
    "node_count": 100,
    "edge_count": 150,
    "format_version": "1.0"
  }
}
```

#### 3.2.2 CSV格式
**节点文件 (nodes.csv)**:
```csv
id,label,type,x,y,attr_age,attr_department
node_1,张三,person,100.0,200.0,30,技术部
node_2,ABC公司,organization,300.0,200.0,,
```

**边文件 (edges.csv)**:
```csv
source,target,type,attr_start_date
node_1,node_2,works_at,2020-01-01
```

## 4. 接口设计

### 4.1 核心接口定义

#### 4.1.1 知识图谱接口
```python
class KnowledgeGraphInterface:
    def add_node(self, node: Node) -> None:
        """添加节点到图中"""
        pass
    
    def add_edge(self, edge: Edge) -> None:
        """添加边到图中"""
        pass
    
    def get_node(self, node_id: str) -> Optional[Node]:
        """根据ID获取节点"""
        pass
    
    def get_neighbors(self, node_id: str) -> List[str]:
        """获取节点的邻居"""
        pass
    
    def search_nodes(self, query: str) -> List[Node]:
        """搜索节点"""
        pass
```

#### 4.1.2 可视化接口
```python
class VisualizationInterface:
    def create_figure(self, kg: KnowledgeGraph, layout_type: str) -> go.Figure:
        """创建可视化图形"""
        pass
    
    def create_network_layout(self, kg: KnowledgeGraph, layout_type: str) -> Dict[str, Tuple[float, float]]:
        """创建网络布局"""
        pass
```

#### 4.1.3 数据导入导出接口
```python
class ImportExportInterface:
    def export_to_json(self, kg: KnowledgeGraph, filepath: str) -> str:
        """导出为JSON格式"""
        pass
    
    def import_from_json(self, source: Union[str, Dict, io.StringIO]) -> KnowledgeGraph:
        """从JSON格式导入"""
        pass
    
    def export_to_csv(self, kg: KnowledgeGraph, nodes_file: str, edges_file: str) -> Tuple[str, str]:
        """导出为CSV格式"""
        pass
```

### 4.2 回调函数接口

#### 4.2.1 主选项卡切换
```python
@app.callback(
    Output('main-tab-content', 'children'),
    [Input('main-tabs', 'value')],
    [State('graph-data', 'data')]
)
def render_tab_content(active_tab, graph_data):
    """渲染选项卡内容"""
    pass
```

#### 4.2.2 文件上传处理
```python
@app.callback(
    Output('graph-data', 'data', allow_duplicate=True),
    [Input('upload-data', 'contents')],
    [State('upload-data', 'filename'), State('graph-data', 'data')],
    prevent_initial_call=True
)
def handle_file_upload(contents, filename, graph_data):
    """处理文件上传"""
    pass
```

#### 4.2.3 图谱交互处理
```python
@app.callback(
    Output('node-details', 'children'),
    [Input('graph-display', 'clickData')],
    [State('graph-data', 'data')]
)
def handle_graph_click(click_data, graph_data):
    """处理图谱点击事件"""
    pass
```

## 5. 算法设计

### 5.1 实体关系抽取算法

#### 5.1.1 实体识别算法
```python
class EntityExtractionAlgorithm:
    def __init__(self):
        self.entity_patterns = {
            'PERSON': [r'[\u4e00-\u9fff]{2,4}(?=先生|女士|教授|博士|经理|总监|主任)', 
                      r'[A-Z][a-z]+\s[A-Z][a-z]+'],
            'ORGANIZATION': [r'[\u4e00-\u9fff]+(?:公司|集团|大学|学院|研究所|部门)',
                           r'[A-Z][a-zA-Z\s]+(?:Inc|Corp|Ltd|University|Institute)'],
            'LOCATION': [r'[\u4e00-\u9fff]+(?:市|省|区|县|街道|路|号)',
                        r'[A-Z][a-zA-Z\s]+(?:City|State|Street|Avenue)']
        }
    
    def extract_entities(self, text: str) -> List[ExtractedEntity]:
        """基于规则和模型的实体抽取"""
        entities = []
        
        # 1. 基于规则的抽取
        rule_entities = self._extract_by_rules(text)
        entities.extend(rule_entities)
        
        # 2. 基于spaCy模型的抽取
        model_entities = self._extract_by_model(text)
        entities.extend(model_entities)
        
        # 3. 实体去重和合并
        entities = self._deduplicate_entities(entities)
        
        return entities
```

#### 5.1.2 关系抽取算法
```python
class RelationExtractionAlgorithm:
    def __init__(self):
        self.relation_patterns = {
            'WORK_FOR': [r'(.+?)(?:在|于)(.+?)(?:工作|任职|就职)',
                        r'(.+?)(?:is|works)\s+(?:at|for)\s+(.+?)'],
            'LOCATED_IN': [r'(.+?)(?:位于|坐落于|在)(.+?)(?:市|省|区)',
                          r'(.+?)\s+(?:is|located)\s+in\s+(.+?)'],
            'PART_OF': [r'(.+?)(?:属于|隶属于)(.+?)(?:部门|组织)',
                       r'(.+?)\s+(?:is|belongs)\s+to\s+(.+?)']
        }
    
    def extract_relations(self, text: str, entities: List[ExtractedEntity]) -> List[ExtractedRelation]:
        """抽取实体间关系"""
        relations = []
        
        # 1. 基于模式匹配的关系抽取
        pattern_relations = self._extract_by_patterns(text, entities)
        relations.extend(pattern_relations)
        
        # 2. 基于依存句法分析的关系抽取
        syntax_relations = self._extract_by_syntax(text, entities)
        relations.extend(syntax_relations)
        
        # 3. 基于语义角色标注的关系抽取
        srl_relations = self._extract_by_srl(text, entities)
        relations.extend(srl_relations)
        
        return relations
```

### 5.2 机器学习增强算法

#### 5.2.1 实体对齐算法
```python
class EntityAlignmentAlgorithm:
    def __init__(self):
        self.similarity_threshold = 0.8
        self.vectorizer = TfidfVectorizer()
    
    def align_entities(self, entities: List[ExtractedEntity]) -> List[List[ExtractedEntity]]:
        """实体对齐算法"""
        # 1. 特征提取
        features = self._extract_features(entities)
        
        # 2. 相似度计算
        similarity_matrix = self._calculate_similarity_matrix(features)
        
        # 3. 聚类分组
        aligned_groups = self._cluster_entities(entities, similarity_matrix)
        
        return aligned_groups
    
    def _calculate_similarity_matrix(self, features: np.ndarray) -> np.ndarray:
        """计算实体间相似度矩阵"""
        # 使用余弦相似度
        similarity_matrix = cosine_similarity(features)
        return similarity_matrix
```

#### 5.2.2 语义消解算法
```python
class SemanticDisambiguationAlgorithm:
    def __init__(self):
        self.context_window = 50  # 上下文窗口大小
        self.embedding_model = None  # 词嵌入模型
    
    def disambiguate_entities(self, entities: List[ExtractedEntity]) -> List[ExtractedEntity]:
        """语义消解算法"""
        disambiguated = []
        
        for entity in entities:
            # 1. 提取上下文特征
            context_features = self._extract_context_features(entity)
            
            # 2. 计算语义向量
            semantic_vector = self._compute_semantic_vector(entity, context_features)
            
            # 3. 消解歧义
            resolved_entity = self._resolve_ambiguity(entity, semantic_vector)
            disambiguated.append(resolved_entity)
        
        return disambiguated
```

#### 5.2.3 关系推理算法
```python
class RelationInferenceAlgorithm:
    def __init__(self):
        self.inference_rules = {
            ('WORK_FOR', 'LOCATED_IN'): 'WORK_IN',  # 传递性推理
            ('PART_OF', 'LOCATED_IN'): 'LOCATED_IN',  # 继承性推理
        }
    
    def infer_relations(self, entities: List[ExtractedEntity], 
                       relations: List[ExtractedRelation]) -> List[ExtractedRelation]:
        """关系推理算法"""
        inferred_relations = []
        
        # 1. 基于规则的推理
        rule_inferred = self._rule_based_inference(entities, relations)
        inferred_relations.extend(rule_inferred)
        
        # 2. 基于图结构的推理
        graph_inferred = self._graph_based_inference(entities, relations)
        inferred_relations.extend(graph_inferred)
        
        # 3. 基于统计的推理
        stat_inferred = self._statistical_inference(entities, relations)
        inferred_relations.extend(stat_inferred)
        
        return inferred_relations
```

### 5.3 知识图谱构建算法

#### 5.3.1 图谱构建流程
```python
class KnowledgeGraphConstructionAlgorithm:
    def __init__(self):
        self.entity_extractor = EntityExtractionAlgorithm()
        self.relation_extractor = RelationExtractionAlgorithm()
        self.ml_enhancer = MLEnhancementAlgorithm()
    
    def construct_from_documents(self, documents: List[str]) -> KnowledgeGraph:
        """从文档构建知识图谱"""
        kg = KnowledgeGraph()
        
        # 1. 文档预处理
        processed_docs = self._preprocess_documents(documents)
        
        # 2. 实体抽取
        all_entities = []
        for doc in processed_docs:
            entities = self.entity_extractor.extract_entities(doc)
            all_entities.extend(entities)
        
        # 3. 关系抽取
        all_relations = []
        for doc in processed_docs:
            doc_entities = [e for e in all_entities if e.source_document == doc]
            relations = self.relation_extractor.extract_relations(doc, doc_entities)
            all_relations.extend(relations)
        
        # 4. 机器学习增强
        enhanced_entities, enhanced_relations = self.ml_enhancer.enhance(
            all_entities, all_relations
        )
        
        # 5. 构建图谱
        kg = self._build_graph(enhanced_entities, enhanced_relations)
        
        return kg
```

### 5.4 图算法应用

### 5.1 布局算法

#### 5.1.1 弹簧布局 (Spring Layout)
```python
def spring_layout(self, kg: KnowledgeGraph, k: float = 3, iterations: int = 50) -> Dict[str, Tuple[float, float]]:
    """
    弹簧布局算法
    
    Args:
        kg: 知识图谱实例
        k: 弹簧常数
        iterations: 迭代次数
    
    Returns:
        节点位置字典
    """
    G = nx.Graph()
    for node_id in kg.nodes:
        G.add_node(node_id)
    for edge in kg.edges.values():
        G.add_edge(edge.source_id, edge.target_id)
    
    pos = nx.spring_layout(G, k=k, iterations=iterations)
    
    # 缩放到合适范围
    scale_factor = min(self.width, self.height) * 0.4
    scaled_pos = {}
    for node_id, (x, y) in pos.items():
        scaled_pos[node_id] = (x * scale_factor, y * scale_factor)
    
    return scaled_pos
```

#### 5.1.2 层次布局 (Hierarchical Layout)
```python
def hierarchical_layout(self, kg: KnowledgeGraph) -> Dict[str, Tuple[float, float]]:
    """
    层次布局算法
    适用于有向图的层次结构展示
    """
    # 使用拓扑排序确定层次
    # 计算每层节点位置
    # 返回位置字典
    pass
```

### 5.2 搜索算法

#### 5.2.1 节点搜索
```python
def search_nodes(self, query: str, search_fields: List[str] = None) -> List[Node]:
    """
    节点搜索算法
    
    Args:
        query: 搜索查询字符串
        search_fields: 搜索字段列表
    
    Returns:
        匹配的节点列表
    """
    if search_fields is None:
        search_fields = ['label', 'type']
    
    results = []
    query_lower = query.lower()
    
    for node in self.nodes.values():
        # 在标签中搜索
        if 'label' in search_fields and query_lower in node.label.lower():
            results.append(node)
            continue
        
        # 在类型中搜索
        if 'type' in search_fields and query_lower in node.type.lower():
            results.append(node)
            continue
        
        # 在属性中搜索
        if 'properties' in search_fields:
            for key, value in node.properties.items():
                if query_lower in str(value).lower():
                    results.append(node)
                    break
    
    return results
```

#### 5.2.2 路径查找
```python
def get_shortest_path(self, source_id: str, target_id: str) -> Optional[List[str]]:
    """
    最短路径算法
    
    Args:
        source_id: 源节点ID
        target_id: 目标节点ID
    
    Returns:
        最短路径节点ID列表
    """
    try:
        return nx.shortest_path(self._nx_graph, source_id, target_id)
    except nx.NetworkXNoPath:
        return None
```

### 5.3 本体生成算法

#### 5.3.1 类层次提取
```python
def extract_class_hierarchy(self, kg: KnowledgeGraph) -> Dict[str, List[str]]:
    """
    从知识图谱中提取类层次结构
    
    Args:
        kg: 知识图谱实例
    
    Returns:
        类层次字典 {parent_class: [child_classes]}
    """
    # 分析节点类型
    # 识别is_a关系
    # 构建层次结构
    pass
```

#### 5.3.2 关系类型分析
```python
def analyze_relation_types(self, kg: KnowledgeGraph) -> Dict[str, Dict[str, Any]]:
    """
    分析关系类型的特征
    
    Args:
        kg: 知识图谱实例
    
    Returns:
        关系类型分析结果
    """
    # 统计关系类型频次
    # 分析关系的域和值域
    # 识别关系属性
    pass
```

## 6. 配置管理

### 6.1 配置文件结构
```json
{
  "app": {
    "title": "知识图谱可视化应用",
    "debug": true,
    "host": "0.0.0.0",
    "port": 8050
  },
  "visualization": {
    "default_layout": "spring",
    "graph_width": 1200,
    "graph_height": 800,
    "node_size_range": [10, 50],
    "edge_width_range": [1, 5]
  },
  "node_colors": {
    "default": "#1f77b4",
    "person": "#ff7f0e",
    "organization": "#2ca02c",
    "location": "#d62728"
  },
  "performance": {
    "max_nodes": 1000,
    "max_edges": 5000,
    "enable_clustering": true
  }
}
```

### 6.2 配置管理类
```python
class Config:
    def __init__(self, config_file: Optional[str] = None):
        self._config = self._load_default_config()
        if config_file and os.path.exists(config_file):
            self.load_from_file(config_file)
    
    def get(self, key: str, default: Any = None) -> Any:
        """获取配置值，支持点号分隔的嵌套键"""
        keys = key.split('.')
        value = self._config
        try:
            for k in keys:
                value = value[k]
            return value
        except (KeyError, TypeError):
            return default
    
    def set(self, key: str, value: Any) -> None:
        """设置配置值"""
        keys = key.split('.')
        config = self._config
        for k in keys[:-1]:
            if k not in config:
                config[k] = {}
            config = config[k]
        config[keys[-1]] = value
```

## 7. 错误处理和日志

### 7.1 异常处理策略

#### 7.1.1 数据验证异常
```python
class DataValidationError(Exception):
    """数据验证异常"""
    pass

class NodeNotFoundError(Exception):
    """节点未找到异常"""
    pass

class EdgeNotFoundError(Exception):
    """边未找到异常"""
    pass
```

#### 7.1.2 文件处理异常
```python
def handle_file_upload(contents, filename, graph_data):
    try:
        # 文件处理逻辑
        pass
    except json.JSONDecodeError as e:
        print(f"JSON格式错误: {e}")
        return dash.no_update
    except UnicodeDecodeError as e:
        print(f"文件编码错误: {e}")
        return dash.no_update
    except Exception as e:
        print(f"文件上传处理失败: {e}")
        return dash.no_update
```

### 7.2 日志管理

#### 7.2.1 日志配置
```python
import logging

def setup_logging(config: Config):
    log_config = config.get('logging', {})
    
    logging.basicConfig(
        level=getattr(logging, log_config.get('level', 'INFO')),
        format=log_config.get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s'),
        handlers=[
            logging.FileHandler(log_config.get('file', './logs/app.log')),
            logging.StreamHandler()
        ]
    )
```

#### 7.2.2 日志记录
```python
logger = logging.getLogger(__name__)

def add_node(self, node: Node) -> None:
    try:
        self.nodes[node.id] = node
        self._nx_graph.add_node(node.id, **node.to_dict())
        logger.info(f"添加节点成功: {node.id}")
    except Exception as e:
        logger.error(f"添加节点失败: {node.id}, 错误: {e}")
        raise
```

## 8. 性能优化

### 8.1 数据处理优化

#### 8.1.1 大规模图谱处理
```python
def optimize_large_graph(self, kg: KnowledgeGraph, max_nodes: int = 1000) -> KnowledgeGraph:
    """
    大规模图谱优化
    
    Args:
        kg: 原始知识图谱
        max_nodes: 最大节点数
    
    Returns:
        优化后的知识图谱
    """
    if len(kg.nodes) <= max_nodes:
        return kg
    
    # 基于重要性采样
    important_nodes = self._select_important_nodes(kg, max_nodes)
    
    # 创建子图
    subgraph = KnowledgeGraph()
    for node_id in important_nodes:
        node = kg.get_node(node_id)
        if node:
            subgraph.add_node(node)
    
    # 添加相关边
    for edge in kg.get_all_edges():
        if edge.source_id in important_nodes and edge.target_id in important_nodes:
            subgraph.add_edge(edge)
    
    return subgraph
```

#### 8.1.2 节点重要性计算
```python
def _select_important_nodes(self, kg: KnowledgeGraph, count: int) -> List[str]:
    """
    基于度中心性选择重要节点
    """
    degree_centrality = nx.degree_centrality(kg._nx_graph)
    sorted_nodes = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)
    return [node_id for node_id, _ in sorted_nodes[:count]]
```

### 8.2 渲染优化

#### 8.2.1 分层渲染
```python
def create_layered_figure(self, kg: KnowledgeGraph, zoom_level: float = 1.0) -> go.Figure:
    """
    分层渲染优化
    根据缩放级别决定渲染详细程度
    """
    if zoom_level < 0.5:
        # 低缩放级别：只显示主要节点
        return self._create_overview_figure(kg)
    elif zoom_level < 1.0:
        # 中等缩放级别：显示部分细节
        return self._create_medium_detail_figure(kg)
    else:
        # 高缩放级别：显示全部细节
        return self._create_full_detail_figure(kg)
```

#### 8.2.2 虚拟化渲染
```python
def create_virtualized_figure(self, kg: KnowledgeGraph, viewport: Dict[str, float]) -> go.Figure:
    """
    虚拟化渲染：只渲染视口内的节点
    
    Args:
        kg: 知识图谱
        viewport: 视口范围 {x_min, x_max, y_min, y_max}
    
    Returns:
        优化后的图形
    """
    visible_nodes = []
    for node in kg.get_all_nodes():
        if (viewport['x_min'] <= node.x <= viewport['x_max'] and
            viewport['y_min'] <= node.y <= viewport['y_max']):
            visible_nodes.append(node)
    
    # 只渲染可见节点和相关边
    return self._create_figure_for_nodes(visible_nodes)
```

## 9. 测试策略

### 9.1 单元测试

#### 9.1.1 数据模型测试
```python
import unittest
from knowledge_graph.node import Node
from knowledge_graph.edge import Edge
from knowledge_graph.graph import KnowledgeGraph

class TestKnowledgeGraph(unittest.TestCase):
    def setUp(self):
        self.kg = KnowledgeGraph()
        self.node1 = Node("n1", "Node 1", "type1")
        self.node2 = Node("n2", "Node 2", "type2")
        self.edge1 = Edge("n1", "n2", "e1", "Edge 1", "relation1")
    
    def test_add_node(self):
        self.kg.add_node(self.node1)
        self.assertTrue(self.kg.has_node("n1"))
        self.assertEqual(self.kg.get_node("n1"), self.node1)
    
    def test_add_edge(self):
        self.kg.add_node(self.node1)
        self.kg.add_node(self.node2)
        self.kg.add_edge(self.edge1)
        self.assertIn("e1", self.kg.edges)
    
    def test_search_nodes(self):
        self.kg.add_node(self.node1)
        results = self.kg.search_nodes("Node")
        self.assertEqual(len(results), 1)
        self.assertEqual(results[0].id, "n1")
```

#### 9.1.2 导入导出测试
```python
class TestImportExport(unittest.TestCase):
    def setUp(self):
        self.kg = KnowledgeGraph()
        self.kg.add_node(Node("n1", "Test Node", "test"))
        self.importer = DataImportExport()
    
    def test_json_export_import(self):
        # 导出到JSON
        json_data = self.importer.export_to_json(self.kg)
        
        # 从JSON导入
        new_kg = self.importer.import_from_json(json_data)
        
        # 验证数据一致性
        self.assertEqual(len(new_kg.nodes), len(self.kg.nodes))
        self.assertEqual(new_kg.get_node("n1").label, "Test Node")
```

### 9.2 集成测试

#### 9.2.1 Web应用测试
```python
import pytest
from dash.testing.application_runners import import_app

def test_app_startup():
    """测试应用启动"""
    app = import_app("web_app.web_app_main")
    assert app is not None

def test_file_upload(dash_duo):
    """测试文件上传功能"""
    app = import_app("web_app.web_app_main")
    dash_duo.start_server(app)
    
    # 模拟文件上传
    # 验证上传结果
    pass
```

### 9.3 性能测试

#### 9.3.1 大数据量测试
```python
def test_large_graph_performance():
    """测试大规模图谱性能"""
    import time
    
    kg = KnowledgeGraph()
    
    # 创建大量节点
    start_time = time.time()
    for i in range(10000):
        node = Node(f"n{i}", f"Node {i}", "test")
        kg.add_node(node)
    
    add_time = time.time() - start_time
    assert add_time < 10.0  # 10秒内完成
    
    # 测试搜索性能
    start_time = time.time()
    results = kg.search_nodes("Node 5000")
    search_time = time.time() - start_time
    assert search_time < 1.0  # 1秒内完成
```

## 10. 部署和维护

### 10.1 部署要求

#### 10.1.1 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: Python 3.8+
- **内存**: 最小4GB，推荐8GB
- **存储**: 最小1GB可用空间
- **网络**: 本地部署，无需外网连接

#### 10.1.2 依赖安装
```bash
# 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# 安装依赖
pip install -r requirements.txt
```

#### 10.1.3 启动脚本
```python
# dev_start.py
if __name__ == "__main__":
    from web_app.web_app_main import create_app
    
    app = create_app()
    app.run_server(
        debug=True,
        host='127.0.0.1',
        port=8050
    )
```

### 10.2 监控和维护

#### 10.2.1 健康检查
```python
def health_check() -> Dict[str, Any]:
    """
    系统健康检查
    
    Returns:
        健康状态信息
    """
    import psutil
    
    return {
        'status': 'healthy',
        'timestamp': pd.Timestamp.now().isoformat(),
        'memory_usage': psutil.virtual_memory().percent,
        'cpu_usage': psutil.cpu_percent(),
        'disk_usage': psutil.disk_usage('/').percent
    }
```

#### 10.2.2 性能监控
```python
def monitor_performance():
    """
    性能监控
    """
    import time
    import functools
    
    def performance_monitor(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            
            logger.info(f"{func.__name__} 执行时间: {end_time - start_time:.2f}秒")
            return result
        return wrapper
    
    return performance_monitor
```

### 10.3 备份和恢复

#### 10.3.1 数据备份
```python
def backup_data(backup_dir: str) -> str:
    """
    数据备份
    
    Args:
        backup_dir: 备份目录
    
    Returns:
        备份文件路径
    """
    import shutil
    from datetime import datetime
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_file = os.path.join(backup_dir, f'backup_{timestamp}.zip')
    
    # 创建备份
    shutil.make_archive(backup_file[:-4], 'zip', './data')
    
    return backup_file
```

#### 10.3.2 数据恢复
```python
def restore_data(backup_file: str, restore_dir: str) -> bool:
    """
    数据恢复
    
    Args:
        backup_file: 备份文件路径
        restore_dir: 恢复目录
    
    Returns:
        恢复是否成功
    """
    import zipfile
    
    try:
        with zipfile.ZipFile(backup_file, 'r') as zip_ref:
            zip_ref.extractall(restore_dir)
        return True
    except Exception as e:
        logger.error(f"数据恢复失败: {e}")
        return False
```

## 11. 扩展性设计

### 11.1 插件架构

#### 11.1.1 插件接口
```python
from abc import ABC, abstractmethod

class PluginInterface(ABC):
    """插件接口"""
    
    @abstractmethod
    def get_name(self) -> str:
        """获取插件名称"""
        pass
    
    @abstractmethod
    def get_version(self) -> str:
        """获取插件版本"""
        pass
    
    @abstractmethod
    def initialize(self, app, config) -> None:
        """初始化插件"""
        pass
    
    @abstractmethod
    def register_callbacks(self, app) -> None:
        """注册回调函数"""
        pass
```

#### 11.1.2 插件管理器
```python
class PluginManager:
    """插件管理器"""
    
    def __init__(self):
        self.plugins = {}
    
    def load_plugin(self, plugin_class) -> None:
        """加载插件"""
        plugin = plugin_class()
        self.plugins[plugin.get_name()] = plugin
    
    def initialize_plugins(self, app, config) -> None:
        """初始化所有插件"""
        for plugin in self.plugins.values():
            plugin.initialize(app, config)
            plugin.register_callbacks(app)
```

### 11.2 API扩展

#### 11.2.1 REST API接口
```python
from flask import Flask, jsonify, request

api_app = Flask(__name__)

@api_app.route('/api/nodes', methods=['GET'])
def get_nodes():
    """获取所有节点"""
    # 实现逻辑
    pass

@api_app.route('/api/nodes', methods=['POST'])
def create_node():
    """创建新节点"""
    # 实现逻辑
    pass

@api_app.route('/api/search', methods=['GET'])
def search_nodes():
    """搜索节点"""
    query = request.args.get('q', '')
    # 实现搜索逻辑
    pass
```

### 11.3 数据源扩展

#### 11.3.1 数据源接口
```python
class DataSourceInterface(ABC):
    """数据源接口"""
    
    @abstractmethod
    def connect(self, connection_string: str) -> bool:
        """连接数据源"""
        pass
    
    @abstractmethod
    def load_data(self) -> KnowledgeGraph:
        """加载数据"""
        pass
    
    @abstractmethod
    def save_data(self, kg: KnowledgeGraph) -> bool:
        """保存数据"""
        pass
```

#### 11.3.2 数据库数据源
```python
class DatabaseDataSource(DataSourceInterface):
    """数据库数据源"""
    
    def connect(self, connection_string: str) -> bool:
        # 连接数据库
        pass
    
    def load_data(self) -> KnowledgeGraph:
        # 从数据库加载数据
        pass
    
    def save_data(self, kg: KnowledgeGraph) -> bool:
        # 保存数据到数据库
        pass
```

---

**文档版本**: 1.0  
**编写日期**: 2024年12月  
**编写人员**: 技术团队  
**审核状态**: 待审核