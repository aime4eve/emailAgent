#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•çŸ¥è¯†å›¾è°±åº”ç”¨çš„æ‰€æœ‰ä¸»è¦åŠŸèƒ½
"""

import sys
import os
import json
import tempfile
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'src'))

from knowledge_graph.graph import KnowledgeGraph
from knowledge_graph.node import Node
from knowledge_graph.edge import Edge
from knowledge_graph.ontology_generator import OntologyGenerator
from visualization.plotly_graph import PlotlyGraphVisualizer
from utils.data_loader import DataLoader
from utils.import_export import DataImportExport
from web_app.interaction_handler import InteractionHandler

def test_knowledge_graph_basic():
    """æµ‹è¯•çŸ¥è¯†å›¾è°±åŸºæœ¬åŠŸèƒ½"""
    print("\n=== æµ‹è¯•çŸ¥è¯†å›¾è°±åŸºæœ¬åŠŸèƒ½ ===")
    
    # åˆ›å»ºçŸ¥è¯†å›¾è°±
    kg = KnowledgeGraph()
    
    # æ·»åŠ èŠ‚ç‚¹
    node1 = Node("1", "å¼ ä¸‰", "äººå‘˜")
    node2 = Node("2", "æå››", "äººå‘˜")
    node3 = Node("3", "é¡¹ç›®A", "é¡¹ç›®")
    
    kg.add_node(node1)
    kg.add_node(node2)
    kg.add_node(node3)
    
    # æ·»åŠ è¾¹
    edge1 = Edge("1", "2", "e1", "åŒäº‹")
    edge2 = Edge("1", "3", "e2", "å‚ä¸")
    
    kg.add_edge(edge1)
    kg.add_edge(edge2)
    
    # éªŒè¯ç»Ÿè®¡ä¿¡æ¯
    stats = kg.get_statistics()
    assert stats['node_count'] == 3, f"èŠ‚ç‚¹æ•°é‡é”™è¯¯: {stats['node_count']}"
    assert stats['edge_count'] == 2, f"è¾¹æ•°é‡é”™è¯¯: {stats['edge_count']}"
    assert 'äººå‘˜' in stats['node_types'], "ç¼ºå°‘äººå‘˜ç±»å‹"
    assert 'é¡¹ç›®' in stats['node_types'], "ç¼ºå°‘é¡¹ç›®ç±»å‹"
    
    print("âœ“ çŸ¥è¯†å›¾è°±åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    return kg

def test_data_import_export(kg):
    """æµ‹è¯•æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½ ===")
    
    import_export = DataImportExport()
    
    # ç¡®ä¿çŸ¥è¯†å›¾è°±æœ‰æ•°æ®
    if len(kg.get_all_nodes()) == 0:
        print("çŸ¥è¯†å›¾è°±ä¸ºç©ºï¼Œè·³è¿‡å¯¼å‡ºæµ‹è¯•")
        return
    
    # æµ‹è¯•JSONå¯¼å‡º
    json_data = import_export.export_to_json(kg, include_metadata=True)
    assert 'nodes' in json_data, "JSONå¯¼å‡ºç¼ºå°‘nodeså­—æ®µ"
    assert 'edges' in json_data, "JSONå¯¼å‡ºç¼ºå°‘edgeså­—æ®µ"
    assert len(json_data['nodes']) == 3, "JSONå¯¼å‡ºèŠ‚ç‚¹æ•°é‡é”™è¯¯"
    
    # æµ‹è¯•JSONå¯¼å…¥
    new_kg = import_export.import_from_json(json_data)
    new_stats = new_kg.get_statistics()
    assert new_stats['node_count'] == 3, "JSONå¯¼å…¥åèŠ‚ç‚¹æ•°é‡é”™è¯¯"
    assert new_stats['edge_count'] == 2, "JSONå¯¼å…¥åè¾¹æ•°é‡é”™è¯¯"
    
    # æµ‹è¯•Excelå¯¼å‡º
    with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp_file:
        excel_path = tmp_file.name
    
    try:
        import_export.export_to_excel(kg, excel_path)
        assert os.path.exists(excel_path), "Excelæ–‡ä»¶å¯¼å‡ºå¤±è´¥"
        
        # æµ‹è¯•Excelå¯¼å…¥
        excel_kg = import_export.import_from_excel(excel_path)
        excel_stats = excel_kg.get_statistics()
        assert excel_stats['node_count'] == 3, "Excelå¯¼å…¥åèŠ‚ç‚¹æ•°é‡é”™è¯¯"
        
        print("âœ“ æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½æµ‹è¯•é€šè¿‡")
    finally:
        if os.path.exists(excel_path):
            try:
                os.unlink(excel_path)
            except:
                pass

def test_ontology_generation(kg):
    """æµ‹è¯•æœ¬ä½“ç”ŸæˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æœ¬ä½“ç”ŸæˆåŠŸèƒ½ ===")
    
    generator = OntologyGenerator()
    
    # ç”Ÿæˆæœ¬ä½“
    ontology = generator.generate_ontology_from_graph(kg)
    
    # éªŒè¯æœ¬ä½“ç»“æ„
    assert hasattr(ontology, 'classes'), "æœ¬ä½“ç¼ºå°‘classeså±æ€§"
    assert hasattr(ontology, 'relations'), "æœ¬ä½“ç¼ºå°‘relationså±æ€§"
    assert len(ontology.relations) > 0, "æœ¬ä½“åº”è¯¥åŒ…å«è‡³å°‘ä¸€ä¸ªå…³ç³»"
    assert len(ontology.classes) > 0, "æœ¬ä½“ç±»ä¸ºç©º"
    
    # æµ‹è¯•å­—å…¸å¯¼å‡º
    json_ontology = ontology.to_dict()
    assert isinstance(json_ontology, dict), "JSONæœ¬ä½“å¯¼å‡ºå¤±è´¥"
    
    # å¯¼å‡ºåˆ°æ–‡ä»¶å¹¶éªŒè¯
    ontology.export_to_json('test_ontology.json')
    ontology.export_to_owl('test_ontology.owl')
    ontology.export_to_rdf('test_ontology.rdf')
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    assert os.path.exists('test_ontology.json'), "JSONæ–‡ä»¶å¯¼å‡ºå¤±è´¥"
    assert os.path.exists('test_ontology.owl'), "OWLæ–‡ä»¶å¯¼å‡ºå¤±è´¥"
    assert os.path.exists('test_ontology.rdf'), "RDFæ–‡ä»¶å¯¼å‡ºå¤±è´¥"
    
    print("âœ“ æœ¬ä½“ç”ŸæˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_visualization(kg):
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½ ===")
    
    visualizer = PlotlyGraphVisualizer()
    
    # æµ‹è¯•ä¸åŒå¸ƒå±€
    layouts = ['spring', 'circular', 'random']
    for layout in layouts:
        try:
            fig = visualizer.create_figure(kg, layout_type=layout)
            assert fig is not None, f"{layout}å¸ƒå±€ç”Ÿæˆå¤±è´¥"
            assert 'data' in fig, f"{layout}å¸ƒå±€å›¾å½¢æ•°æ®ç¼ºå¤±"
            print(f"âœ“ {layout}å¸ƒå±€æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âš  {layout}å¸ƒå±€æµ‹è¯•å¤±è´¥: {e}")
    
    print("âœ“ å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_interaction_handler(kg):
    """æµ‹è¯•äº¤äº’å¤„ç†åŠŸèƒ½"""
    print("\n=== æµ‹è¯•äº¤äº’å¤„ç†åŠŸèƒ½ ===")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨å’Œé…ç½®
    visualizer = PlotlyGraphVisualizer()
    config = {'layout': 'spring', 'node_size': 10}
    
    handler = InteractionHandler(kg, visualizer, config)
    
    # æµ‹è¯•æ·»åŠ èŠ‚ç‚¹
    success = handler.add_node("test_node", "æµ‹è¯•èŠ‚ç‚¹", "æµ‹è¯•ç±»å‹")
    assert success, "æ·»åŠ èŠ‚ç‚¹å¤±è´¥"
    
    # æµ‹è¯•èŠ‚ç‚¹é€‰æ‹©
    handler.select_node("test_node")
    selected = handler.get_selected_nodes()
    assert "test_node" in selected, "èŠ‚ç‚¹é€‰æ‹©å¤±è´¥"
    
    # æµ‹è¯•æ¸…é™¤é€‰æ‹©
    handler.clear_selection()
    selected = handler.get_selected_nodes()
    assert len(selected) == 0, "æ¸…é™¤é€‰æ‹©å¤±è´¥"
    
    print("âœ“ äº¤äº’å¤„ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½ ===")
    
    loader = DataLoader()
    
    # æµ‹è¯•åˆ›å»ºç¤ºä¾‹æ•°æ®
    try:
        sample_kg = loader.create_sample_data()
        if sample_kg:
            stats = sample_kg.get_statistics()
            assert stats['node_count'] > 0, "ç¤ºä¾‹æ•°æ®èŠ‚ç‚¹ä¸ºç©º"
            print(f"âœ“ æˆåŠŸåˆ›å»ºç¤ºä¾‹æ•°æ®: {stats['node_count']}ä¸ªèŠ‚ç‚¹, {stats['edge_count']}æ¡è¾¹")
        else:
            print("âš  ç¤ºä¾‹æ•°æ®åˆ›å»ºå¤±è´¥ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½")
    except Exception as e:
        print(f"âš  æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹å…¨åŠŸèƒ½æµ‹è¯•...")
    
    try:
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
        kg = test_knowledge_graph_basic()
        
        # æ•°æ®å¯¼å…¥å¯¼å‡ºæµ‹è¯•
        test_data_import_export(kg)
        
        # æœ¬ä½“ç”Ÿæˆæµ‹è¯•
        test_ontology_generation(kg)
        
        # å¯è§†åŒ–æµ‹è¯•
        test_visualization(kg)
        
        # äº¤äº’å¤„ç†æµ‹è¯•
        test_interaction_handler(kg)
        
        # æ•°æ®åŠ è½½æµ‹è¯•
        test_data_loader()
        
        print("\nğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)